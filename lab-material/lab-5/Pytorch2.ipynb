{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SI-aeAGi5BBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CMPT 732 - Fall 2022\n",
        "# PyTorch tutorial - Part II\n",
        "\n",
        "__content creator:__ Aryan Mikaeili"
      ],
      "metadata": {
        "id": "_cGj4QjM5BsH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up Colab\n",
        "\n",
        "1. Opening the notebook\n",
        "2. Changing runtime type to GPU\n"
      ],
      "metadata": {
        "id": "xQRST7NV4efg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing PyTorch\n",
        "\n",
        "Go to https://pytorch.org/. There you can find instructions on how to install PyTorch based on your machine. If using Lab machines, no need to install PyTorch."
      ],
      "metadata": {
        "id": "rYUHCSkA4yAm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensors\n",
        "\n",
        "Four important attributes:\n",
        "1. Data\n",
        "2. Type\n",
        "3. Device\n",
        "4. Requires Grad"
      ],
      "metadata": {
        "id": "_cKDX_0V7way"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "J94wVgPP7v2y"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining an empty tensor and observing the default attributes\n",
        "t = torch.tensor([1, 2, 3])\n",
        "\n",
        "print('type:', type(t))\n",
        "print('dtype:', t.dtype)\n",
        "print('device:', t.device)\n",
        "print('requires grad:', t.requires_grad)\n"
      ],
      "metadata": {
        "id": "_8GuEroe8GrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining an arbitrary tensor\n",
        "\n",
        "t = torch.tensor(np.array([1, 2, 3]), dtype=torch.float64, device='cuda:0',requires_grad=True)\n",
        "\n",
        "print('type:', type(t))\n",
        "print('dtype:', t.dtype)\n",
        "print('device:', t.device)\n",
        "print('requires grad:', t.requires_grad)"
      ],
      "metadata": {
        "id": "djJ4KWE18m7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Controlling devices in PyTorch\n"
      ],
      "metadata": {
        "id": "S-husWAJ9KTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.tensor([], device = torch.device('cpu'))\n",
        "\n",
        "print('t1 device:', t1.device)\n",
        "\n",
        "t2 = t1.cuda()\n",
        "print('t2 device:', t2.device)\n",
        "\n",
        "t3 = t1.cpu()\n",
        "print('t3 device:', t1.device)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PQOpml4b9JKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0')\n",
        "\n",
        "t = torch.tensor([])\n",
        "\n",
        "t1 = t.to(device)\n",
        "\n",
        "print('t1 device:', t1.device)"
      ],
      "metadata": {
        "id": "advjUllDoboW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(torch.cuda.is_available())\n",
        "print('device:', device)\n"
      ],
      "metadata": {
        "id": "2YRYVqiQ9yTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Accessing an item in PyTorch"
      ],
      "metadata": {
        "id": "LK7QhQoY_Iuy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "t = torch.tensor([1, 2, 3])\n",
        "print(t[1])\n",
        "\n",
        "n = np.array([1, 2, 3])\n",
        "print(n[1])\n"
      ],
      "metadata": {
        "id": "rRJMb2zc_H8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(t[1].item())"
      ],
      "metadata": {
        "id": "jk2Lx7LZ_b3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Converting tensors to and from numpy arrays"
      ],
      "metadata": {
        "id": "fRMA7upY_lM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor([1, 2, 3])\n",
        "n = t.numpy()\n",
        "\n",
        "print('n:',n)\n",
        "tn = torch.from_numpy(n)\n",
        "print('tn:',tn)\n",
        "\n"
      ],
      "metadata": {
        "id": "VAPcuRfy_gHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Important operations on tensors"
      ],
      "metadata": {
        "id": "fgI7QxewC1SF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#unsqueeze\n",
        "t = torch.tensor([1, 2, 3])\n",
        "\n",
        "t_u = torch.unsqueeze(t, 0)\n",
        "print('t shape:', t.shape)\n",
        "print('t_u shape:', t_u.shape)"
      ],
      "metadata": {
        "id": "wuMV2v3ECuxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cat\n",
        "a = torch.randn((8, 3))\n",
        "b = torch.randn((4, 3))\n",
        "\n",
        "c = torch.cat([a, b], dim = 0)\n",
        "\n",
        "print(c.shape)"
      ],
      "metadata": {
        "id": "O1E2PrZsNoos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#permute\n",
        "a = torch.randn((4, 100, 200, 3))\n",
        "\n",
        "a_perm = a.permute((0, 3, 1, 2))\n",
        "\n",
        "print(a_perm.shape)\n"
      ],
      "metadata": {
        "id": "SwNP1QlqN5NG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#matrix multiplication\n",
        "\n",
        "a = torch.randn(4, 3)\n",
        "b = torch.randn(3, 5)\n",
        "\n",
        "ab_mult = a @ b\n",
        "print(ab_mult.shape)"
      ],
      "metadata": {
        "id": "BsiERyzhOIZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#batch matrix multiplication\n",
        "\n",
        "a = torch.randn(100, 4, 3)\n",
        "b = torch.randn(100, 3, 5)\n",
        "\n",
        "ab_mult = torch.bmm(a, b)\n",
        "print(ab_mult.shape)"
      ],
      "metadata": {
        "id": "9msrg5MSOZzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#inplace operations\n"
      ],
      "metadata": {
        "id": "ZAaZxoYjPDJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autograd Package"
      ],
      "metadata": {
        "id": "x23RSUSRReG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N, D = 3, 4\n",
        "\n",
        "x = torch.randn(N, D, requires_grad=True)\n",
        "y = torch.randn(N, D)\n",
        "z = torch.randn(N, D)\n",
        "\n",
        "a = x * y\n",
        "b = a + z\n",
        "c = b.sum()\n",
        "\n"
      ],
      "metadata": {
        "id": "ebFI3YUUQyDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#backward"
      ],
      "metadata": {
        "id": "LpYu6_PQzOIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#computation graph and the backward method"
      ],
      "metadata": {
        "id": "78JQJLK1zQlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#accumulation of gradients in the backward method"
      ],
      "metadata": {
        "id": "Uk0r9gOczXTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# the NN module"
      ],
      "metadata": {
        "id": "09-pQEGFc1ZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "l = nn.Linear(in_features = 1000, out_features = 100, bias = True)\n",
        "\n",
        "x = torch.randn(64, 1000)\n",
        "\n",
        "output = l(x)\n",
        "\n",
        "print('shape of output:', output.shape)\n"
      ],
      "metadata": {
        "id": "q_Dc5LY3c0vI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('weight shape:',l.weight.shape)\n",
        "print('bias shape:',l.bias.shape)\n",
        "print('type of weight', type(l.weight))"
      ],
      "metadata": {
        "id": "x94QOve_R9gN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv2d = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5)\n",
        "image = torch.randn(100, 100, 3)\n",
        "\n",
        "image = torch.unsqueeze(image, 0)\n",
        "print('image shape 1:', image.shape)\n",
        "\n",
        "image = image.permute(0, 3, 1, 2)\n",
        "print('image shape 2:',image.shape)\n",
        "\n",
        "output = conv2d(image)\n",
        "\n",
        "print('output shape:',output.shape)\n",
        "\n",
        "print('weights shape:', conv2d.weight.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "rmCifJcgeDey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv2d = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5)\n",
        "image = torch.randn(100, 100, 3)\n",
        "\n",
        "\n",
        "image = torch.unsqueeze(image, 0)\n",
        "print('image shape 1:', image.shape)\n",
        "\n",
        "\n",
        "image = image.permute(0, 3, 1, 2)\n",
        "print('image shape 2:',image.shape)\n",
        "\n",
        "output = conv2d(image)\n",
        "\n",
        "print('output shape:',output.shape)"
      ],
      "metadata": {
        "id": "r4bmfwgI7YK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(conv2d.weight.shape)"
      ],
      "metadata": {
        "id": "-uTGgl0890TL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datasets, Dataloaders and Torchvision transforms"
      ],
      "metadata": {
        "id": "vXHfIbX1ienJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#transforms\n",
        "\n",
        "#download image\n",
        "import requests\n",
        "import shutil\n",
        "from PIL import Image\n",
        "\n",
        "image_url = 'https://upload.wikimedia.org/wikipedia/commons/6/6a/Johann_Sebastian_Bach.jpg'\n",
        "response = requests.get(image_url, stream=True)\n",
        "with open('bach.jpg', 'wb') as f:\n",
        "  shutil.copyfileobj(response.raw, f)\n",
        "\n",
        "image = Image.open('bach.jpg')\n"
      ],
      "metadata": {
        "id": "M_AxBdxcwV_g"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#transfer to tensor\n",
        "from torchvision import transforms\n",
        "\n",
        "image_tensor = transforms.ToTensor()(image)\n",
        "print(type(image), type(image_tensor))\n",
        "print(image_tensor.shape)"
      ],
      "metadata": {
        "id": "BMRtCvt5xmoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Horizontal flip\n",
        "\n",
        "hflip_image = transforms.RandomHorizontalFlip(1)(image)\n",
        "Image.fromarray(np.hstack([np.array(image), np.array(hflip_image)]))"
      ],
      "metadata": {
        "id": "AtbbnJiFx8mG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Rotate image\n",
        "\n",
        "rotate_image = transforms.RandomRotation(30)(image)\n",
        "Image.fromarray(np.hstack([np.array(image), np.array(rotate_image)]))\n"
      ],
      "metadata": {
        "id": "i9HmhfYOyQku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalize\n"
      ],
      "metadata": {
        "id": "2WoZdP1yylEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1yFOjoinw33o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Available datasets\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "b_size = 4\n",
        "\n",
        "trainset = datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=b_size,\n",
        "                                           shuffle=True, num_workers=0)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kV_lSIr-id_X",
        "outputId": "c087e7c6-74d4-4dda-bdf8-4259d5c5d51b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image, label = trainset.__getitem__(1)\n",
        "image = image.permute(1, 2, 0).numpy()\n",
        "\n",
        "image = ((image + 1) * 127.5).astype('uint8')\n",
        "plt.imshow(image)\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "K4mPqYCpjIof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, data in enumerate(trainloader):\n",
        "  images, labels = data\n",
        "  print(i, images.shape, labels.shape)"
      ],
      "metadata": {
        "id": "81R68URYjy17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#arbitrary dataset\n",
        "import torch\n",
        "images = torch.randn(100, 3, 32, 32)\n",
        "labels = torch.randint(10, (100,))\n",
        "\n",
        "\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class my_data(Dataset):\n",
        "  def __init__(self, images, labels):\n",
        "    super().__init__()\n",
        "    self.images = images\n",
        "    self.labels = labels\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "    return self.images[idx], self.labels[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.images.shape[0]\n",
        "\n",
        "\n",
        "dataset = my_data(images, labels)\n",
        "dataloader = DataLoader(dataset, batch_size = 8, shuffle=True, drop_last=True)\n",
        "\n",
        "\n",
        "for i, data in enumerate(dataloader):\n",
        "  images, labels = data\n",
        "  print(i, images.shape, labels.shape)"
      ],
      "metadata": {
        "id": "tJ2fIVSFkEC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise\n",
        "\n",
        "Cifar10 classifier with the following structure (see the attached framework):\n",
        "\n",
        "__two Convolutional blocks__\n",
        "1. 2D convolution layer: 3 channels (first block) 16 channels (second block) to 16 channels with kernel size 5\n",
        "2. ReLU activation\n",
        "3. 2D max pooling layer\n",
        "\n",
        "__Flatten__\n",
        "\n",
        "1. Linear layer with appropriate number of input nodes and 128 output nodes + ReLU\n",
        "2. Linear layer with 128 input nodes and 64 output nodes + ReLU\n",
        "3. Linear Layer with 64 input nodes and 10 output nodes\n"
      ],
      "metadata": {
        "id": "-7bzyUg5bark"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sv4uy12_lh7x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}